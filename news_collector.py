import requests
from bs4 import BeautifulSoup
from telegram import Bot
from datetime import datetime, timedelta
import asyncio
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
import os

# í…”ë ˆê·¸ë¨ ì„¤ì •
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN', '7873086292:AAEthtBcUFopzyKY5a3UPBlGdNzP5BrDBIM')
PERSONAL_CHAT_ID = os.environ.get('PERSONAL_CHAT_ID', '7882172599')  # ê°œì¸ ì±„íŒ… ID
CHANNEL_CHAT_ID = os.environ.get('CHANNEL_CHAT_ID', '-1002303882674')  # ì±„ë„ ID

# ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë° ê²€ìƒ‰ í‚¤ì›Œë“œ ì„¤ì •
NEWS_CATEGORIES = {
    'LLM/AI': {
        'urls': [
            # ë„¤ì´ë²„ ë‰´ìŠ¤ - ë‹¤ì–‘í•œ ê²€ìƒ‰ì–´ë¡œ ì‹œë„
            'https://search.naver.com/search.naver?where=news&query=ì¸ê³µì§€ëŠ¥+AI+ì‹ ê·œ+ì¶œì‹œ+ë°œí‘œ&sort=1&pd=4',
            'https://search.naver.com/search.naver?where=news&query=AI+ëª¨ë¸+LLM+ìƒˆë¡œìš´&sort=1&pd=4',
            'https://search.naver.com/search.naver?where=news&query=ìƒì„±í˜•+AI+ëŒ€í˜•ì–¸ì–´ëª¨ë¸+ë°œí‘œ&sort=1&pd=4',
            'https://search.naver.com/search.naver?where=news&query=AI+ê¸°ì—…+ì‹ ì œí’ˆ+ì¶œì‹œ&sort=1&pd=4'
        ],
        'selectors': {
            'naver': {
                'article': '.news_wrap',
                'title': '.news_tit',
                'link': '.news_tit',
                'time': '.info_group span:nth-child(3)',
                'press': '.info_group a.press'
            }
        },
        'keywords': [
            'AI', 'ì¸ê³µì§€ëŠ¥', 'LLM', 'ì–¸ì–´ëª¨ë¸', 'ìƒì„±í˜•',
            'ì¶œì‹œ', 'ë°œí‘œ', 'ê³µê°œ', 'ìƒˆë¡œìš´', 'ì‹ ê·œ',
            'ë²„ì „', 'ì—…ë°ì´íŠ¸', 'ê°œì„ ', 'ë°œì „'
        ]
    }
}

class NewsCollector:
    def __init__(self):
        self.bot = Bot(token=TELEGRAM_TOKEN)
        
        # Chrome ì˜µì…˜ ì„¤ì •
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36')
        
        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)

    async def get_news(self, url_or_config):
        try:
            if isinstance(url_or_config, dict):
                all_news = set()  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ set ì‚¬ìš©
                
                for url in url_or_config['urls']:
                    try:
                        self.driver.get(url)
                        await asyncio.sleep(2)
                        
                        selectors = url_or_config['selectors']['naver']
                        wait = WebDriverWait(self.driver, 10)
                        articles = wait.until(EC.presence_of_all_elements_located(
                            (By.CSS_SELECTOR, selectors['article'])
                        ))
                        
                        for article in articles:
                            try:
                                title_element = article.find_element(By.CSS_SELECTOR, selectors['title'])
                                title = title_element.get_attribute('title') or title_element.text
                                link = article.find_element(By.CSS_SELECTOR, selectors['link']).get_attribute('href')
                                
                                time_text = ""
                                try:
                                    time_element = article.find_element(By.CSS_SELECTOR, selectors['time'])
                                    time_text = time_element.text.strip()
                                except:
                                    pass

                                if title and link and any(keyword.lower() in title.lower() for keyword in url_or_config['keywords']):
                                    title_with_time = f"[NAVER] {title}"
                                    if time_text:
                                        title_with_time = f"[NAVER/{time_text}] {title}"
                                    
                                    # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ë§í¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¶”ê°€
                                    all_news.add((title_with_time, link))
                                    
                                    if len(all_news) >= 10:
                                        break
                                        
                            except Exception as e:
                                print(f"ê¸°ì‚¬ íŒŒì‹± ì¤‘ ì—ëŸ¬: {e}")
                                continue
                                
                        if len(all_news) >= 10:
                            break
                            
                    except Exception as e:
                        print(f"URL ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
                        continue
                
                # setì„ listë¡œ ë³€í™˜í•˜ê³  ìµœì‹  10ê°œ ë°˜í™˜
                return [{'title': title, 'link': link} for title, link in list(all_news)[:10]]
            else:  # ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì˜ ê²½ìš°
                self.driver.get(url_or_config)
                wait = WebDriverWait(self.driver, 10)
                articles = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.news_area')))
                
                news_list = []
                for article in articles[:10]:
                    try:
                        title_element = article.find_element(By.CSS_SELECTOR, 'a.news_tit')
                        title = title_element.get_attribute('title')
                        link = title_element.get_attribute('href')
                        
                        if title and link:
                            news_list.append({'title': title, 'link': link})
                    except Exception as e:
                        print(f"ê°œë³„ ë‰´ìŠ¤ íŒŒì‹± ì¤‘ ì—ëŸ¬: {e}")
                        continue
                
                return news_list
        except Exception as e:
            print(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬: {e}")
            return []

    async def send_telegram_message(self, message):
        # ë‘ ì±„íŒ…ë°© ëª¨ë‘ì— ë©”ì‹œì§€ ì „ì†¡
        await self.bot.send_message(chat_id=PERSONAL_CHAT_ID, text=message, parse_mode='HTML')
        await self.bot.send_message(chat_id=CHANNEL_CHAT_ID, text=message, parse_mode='HTML')

    async def collect_and_send(self):
        # KST ê¸°ì¤€ìœ¼ë¡œ ë‚ ì§œ ì„¤ì •
        kst = datetime.now() + timedelta(hours=9)  # UTC to KST
        today = kst.strftime('%Yë…„ %mì›” %dì¼')
        
        full_message = f"ğŸ“° {today} ë‰´ìŠ¤ ìš”ì•½\n\n"
        
        # AI ë‰´ìŠ¤ ìˆ˜ì§‘
        for category, url_or_config in NEWS_CATEGORIES.items():
            try:
                news_list = await self.get_news(url_or_config)
                if news_list:
                    full_message += f"â”â”â” {category} â”â”â”\n\n"
                    for idx, news in enumerate(news_list, 1):
                        # HTML íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬
                        title = news['title'].replace('<', '&lt;').replace('>', '&gt;')
                        full_message += f"{idx}. <a href='{news['link']}'>{title}</a>\n"
                    full_message += "\n"
            except Exception as e:
                print(f"{category} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
                continue
        
        # ì¸ê¸° ë‰´ìŠ¤ ì¶”ê°€
        popular_news = await self.get_popular_news()
        full_message += f"\n{popular_news}"
        
        # ë‘ ì±„íŒ…ë°© ëª¨ë‘ì— ë©”ì‹œì§€ ì „ì†¡
        await self.bot.send_message(chat_id=PERSONAL_CHAT_ID, text=full_message, parse_mode='HTML')
        await self.bot.send_message(chat_id=CHANNEL_CHAT_ID, text=full_message, parse_mode='HTML')

    async def get_popular_news(self):
        try:
            # ê° ì–¸ë¡ ì‚¬ë³„ URL
            press_urls = {
                'ì—°í•©ë‰´ìŠ¤': 'https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1=001&listType=summary&oid=001',
                'KBS': 'https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1=001&listType=summary&oid=056',
                'MBC': 'https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1=001&listType=summary&oid=214',
                'YTN': 'https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1=001&listType=summary&oid=052',
                'JTBC': 'https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1=001&listType=summary&oid=437'
            }
            
            popular_news = "ğŸ“° ì£¼ìš” ë°©ì†¡ì‚¬ ë‰´ìŠ¤\n\n"
            
            for press, url in press_urls.items():
                try:
                    print(f"Collecting news from {press}...")
                    self.driver.get(url)
                    await asyncio.sleep(3)
                    
                    # ê¸°ì‚¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° - MBCìš© ì…€ë ‰í„° ì¶”ê°€
                    if press == 'MBC':
                        wait = WebDriverWait(self.driver, 10)
                        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '#main_content .list_body')))
                        articles = self.driver.find_elements(By.CSS_SELECTOR, '#main_content .list_body .type06_headline li, #main_content .list_body .type06 li')
                    else:
                        articles = self.driver.find_elements(By.CSS_SELECTOR, '.type06_headline li, .type06 li')
                    
                    # ê° ì–¸ë¡ ì‚¬ë³„ ìµœì‹  10ê°œ ê¸°ì‚¬ ìˆ˜ì§‘
                    popular_news += f"[{press}]\n"
                    news_count = 0
                    collected_titles = set()  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ set
                    
                    for article in articles:
                        try:
                            title_element = article.find_element(By.CSS_SELECTOR, 'dt:not(.photo) > a')
                            title = title_element.text.strip()
                            link = title_element.get_attribute('href')
                            
                            # ì¤‘ë³µ ê¸°ì‚¬ ê±´ë„ˆë›°ê¸°
                            if title in collected_titles:
                                continue
                                
                            if title and link:
                                # HTML íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬
                                title = title.replace('<', '&lt;').replace('>', '&gt;')
                                popular_news += f"â€¢ <a href='{link}'>{title}</a>\n"
                                news_count += 1
                                collected_titles.add(title)  # ì œëª© ì¶”ê°€
                                
                                if news_count >= 10:
                                    break
                                    
                        except Exception as e:
                            continue
                    
                    popular_news += "\n"
                    
                except Exception as e:
                    print(f"Error collecting news from {press}: {e}")
                    continue
            
            return popular_news
        except Exception as e:
            print(f"ì£¼ìš” ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬: {e}")
            return "ì£¼ìš” ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"

    def __del__(self):
        if hasattr(self, 'driver'):
            self.driver.quit()

async def main():
    collector = NewsCollector()
    await collector.collect_and_send()

if __name__ == "__main__":
    asyncio.run(main()) 