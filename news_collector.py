import requests
from bs4 import BeautifulSoup
from telegram import Bot
from datetime import datetime, timedelta
import asyncio
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options

# í…”ë ˆê·¸ë¨ ì„¤ì •
TELEGRAM_TOKEN = "7873086292:AAEthtBcUFopzyKY5a3UPBlGdNzP5BrDBIM"
CHAT_ID = "7882172599"

# ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë° ê²€ìƒ‰ í‚¤ì›Œë“œ ì„¤ì •
NEWS_CATEGORIES = {
    'LLM/AI': {
        'urls': [
            # ë„¤ì´ë²„ ë‰´ìŠ¤ë§Œ ìš°ì„  ì‚¬ìš©
            'https://search.naver.com/search.naver?where=news&query=AI+ì¸ê³µì§€ëŠ¥+ChatGPT&sort=1&pd=4',
        ],
        'selectors': {
            'naver': {
                'article': '.news_wrap',
                'title': '.news_tit',
                'link': '.news_tit',
                'time': '.info_group span:nth-child(3)'
            }
        },
        'keywords': [
            'GPT', 'AI', 'ì¸ê³µì§€ëŠ¥', 'LLM', 'Claude', 'Gemini',
            'ChatGPT', 'ìƒì„±í˜•', 'ì±—ë´‡', 'ë¨¸ì‹ ëŸ¬ë‹', 'ë”¥ëŸ¬ë‹'
        ]
    }
}

class NewsCollector:
    def __init__(self):
        self.bot = Bot(token=TELEGRAM_TOKEN)
        
        # Chrome ì˜µì…˜ ì„¤ì •
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36')
        
        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)

    async def get_news(self, url_or_config):
        try:
            if isinstance(url_or_config, dict):
                all_news = []
                
                for url in url_or_config['urls']:
                    try:
                        self.driver.get(url)
                        await asyncio.sleep(2)
                        
                        # URLì— ë”°ë¥¸ ì…€ë ‰í„° ì„ íƒ
                        selector_key = 'naver' if 'naver.com' in url else \
                                     'daum' if 'daum.net' in url else \
                                     'aitimes' if 'aitimes.com' in url else 'naver'
                        
                        selectors = url_or_config['selectors'][selector_key]
                        wait = WebDriverWait(self.driver, 10)
                        articles = wait.until(EC.presence_of_all_elements_located(
                            (By.CSS_SELECTOR, selectors['article'])
                        ))
                        
                        # LLM/AI ë‰´ìŠ¤ëŠ” 10ê°œê¹Œì§€ ìˆ˜ì§‘
                        for article in articles[:15]:  # ì—¬ìœ ìˆê²Œ 15ê°œ ê²€ì‚¬
                            try:
                                title_element = article.find_element(By.CSS_SELECTOR, selectors['title'])
                                title = title_element.get_attribute('title') or title_element.text
                                link = article.find_element(By.CSS_SELECTOR, selectors['link']).get_attribute('href')
                                
                                time_text = ""
                                try:
                                    time_element = article.find_element(By.CSS_SELECTOR, selectors['time'])
                                    time_text = time_element.text.strip()
                                except:
                                    pass

                                source = 'NAVER' if 'naver.com' in url else \
                                        'DAUM' if 'daum.net' in url else \
                                        'AIíƒ€ì„ìŠ¤' if 'aitimes.com' in url else ''
                                
                                if title and link and any(keyword.lower() in title.lower() for keyword in url_or_config['keywords']):
                                    title_with_time = f"[{source}] {title}"
                                    if time_text:
                                        title_with_time = f"[{source}/{time_text}] {title}"
                                    
                                    print(f"Found news: {title_with_time}")
                                    all_news.append({
                                        'title': title_with_time,
                                        'link': link
                                    })
                            except Exception as e:
                                print(f"ê¸°ì‚¬ íŒŒì‹± ì¤‘ ì—ëŸ¬: {e}")
                                continue
                    except Exception as e:
                        print(f"URL ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ({url}): {e}")
                        continue
                
                return all_news[:10]  # ìµœëŒ€ 10ê°œ ë°˜í™˜
            else:  # ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì˜ ê²½ìš°
                self.driver.get(url_or_config)
                wait = WebDriverWait(self.driver, 10)
                articles = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.news_area')))
                
                news_list = []
                for article in articles[:10]:
                    try:
                        title_element = article.find_element(By.CSS_SELECTOR, 'a.news_tit')
                        title = title_element.get_attribute('title')
                        link = title_element.get_attribute('href')
                        
                        if title and link:
                            print(f"Found news: {title}")
                            news_list.append({'title': title, 'link': link})
                    except Exception as e:
                        print(f"ê°œë³„ ë‰´ìŠ¤ íŒŒì‹± ì¤‘ ì—ëŸ¬: {e}")
                        continue
                
                return news_list
        except Exception as e:
            print(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬: {e}")
            return []

    async def send_telegram_message(self, message):
        await self.bot.send_message(chat_id=CHAT_ID, text=message, parse_mode='HTML')

    async def collect_and_send(self):
        today = datetime.now().strftime('%Yë…„ %mì›” %dì¼')
        full_message = f"ğŸ“° {today} ë‰´ìŠ¤ ìš”ì•½\n\n"
        
        # AI ë‰´ìŠ¤ ìˆ˜ì§‘
        for category, url_or_config in NEWS_CATEGORIES.items():
            try:
                news_list = await self.get_news(url_or_config)
                if news_list:
                    full_message += f"â”â”â” {category} â”â”â”\n\n"
                    for idx, news in enumerate(news_list, 1):
                        title = news['title'].replace('<', '').replace('>', '')
                        # ë§í¬ë¥¼ ì œëª©ì— í¬í•¨
                        full_message += f"{idx}. <a href='{news['link']}'>{title}</a>\n"
                    full_message += "\n"
            except Exception as e:
                print(f"{category} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
                continue
        
        # ì¸ê¸° ë‰´ìŠ¤ ì¶”ê°€
        popular_news = await self.get_popular_news()
        full_message += f"\n{popular_news}"
        
        # ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ
        if len(full_message) > 4000:
            full_message = full_message[:4000] + "\n\n... (ë” ë§ì€ ë‰´ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤)"
        
        # HTML ëª¨ë“œ ë‹¤ì‹œ í™œì„±í™”
        await self.bot.send_message(chat_id=CHAT_ID, text=full_message, parse_mode='HTML')

    async def get_popular_news(self):
        try:
            # ê° ì–¸ë¡ ì‚¬ë³„ URL
            press_urls = {
                'ì—°í•©ë‰´ìŠ¤': 'https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1=001&listType=summary&oid=001',
                'KBS': 'https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1=001&listType=summary&oid=056',
                'MBC': 'https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1=001&listType=summary&oid=214',
                'YTN': 'https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1=001&listType=summary&oid=052',
                'JTBC': 'https://news.naver.com/main/list.naver?mode=LSD&mid=sec&sid1=001&listType=summary&oid=437'
            }
            
            popular_news = "ğŸ“° ì£¼ìš” ë°©ì†¡ì‚¬ ë‰´ìŠ¤\n\n"
            
            for press, url in press_urls.items():
                try:
                    self.driver.get(url)
                    await asyncio.sleep(1)
                    wait = WebDriverWait(self.driver, 10)
                    
                    # ëª¨ë“  ê¸°ì‚¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                    articles = []
                    for selector in ['.type06_headline li', '.type06 li']:
                        articles.extend(wait.until(EC.presence_of_all_elements_located(
                            (By.CSS_SELECTOR, selector)
                        )))
                    
                    # ê° ì–¸ë¡ ì‚¬ë³„ ìµœì‹  5ê°œ í…ìŠ¤íŠ¸ ê¸°ì‚¬ ìˆ˜ì§‘
                    popular_news += f"[{press}]\n"  # ì–¸ë¡ ì‚¬ ì œëª© ì¶”ê°€
                    news_count = 0
                    for article in articles:
                        try:
                            # ë™ì˜ìƒ ê¸°ì‚¬ ì œì™¸
                            if 'ë™ì˜ìƒ' in article.text:
                                continue
                                
                            title_element = article.find_element(By.CSS_SELECTOR, 'dt:not(.photo) > a')
                            title = title_element.text.strip()
                            link = title_element.get_attribute('href')
                            
                            if title and link:
                                title = title.replace('<', '').replace('>', '')
                                popular_news += f"â€¢ <a href='{link}'>{title}</a>\n"
                                news_count += 1
                                
                                if news_count >= 5:  # 5ê°œ ìˆ˜ì§‘í•˜ë©´ ì¤‘ë‹¨
                                    break
                                    
                        except Exception as e:
                            continue
                    
                    popular_news += "\n"  # ì–¸ë¡ ì‚¬ êµ¬ë¶„ì„ ìœ„í•œ ë¹ˆ ì¤„
                    
                except Exception as e:
                    continue
            
            return popular_news
        except Exception as e:
            print(f"ì£¼ìš” ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬: {e}")
            return "ì£¼ìš” ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"

    async def get_google_news(self):
        try:
            url = "https://news.google.com/search?q=AI%20LLM%20GPT%20when:1d&hl=ko&gl=KR"
            self.driver.get(url)
            wait = WebDriverWait(self.driver, 10)
            
            # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
            await asyncio.sleep(3)
            
            # êµ¬ê¸€ ë‰´ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            articles = wait.until(EC.presence_of_all_elements_located(
                (By.CSS_SELECTOR, 'article.MQsxIb.xTewfe.R7GTQ.keNKEd.j7vNaf.Cc0Z5d.EjqUne')
            ))
            
            google_news = "ğŸŒ í•´ì™¸ AI ë‰´ìŠ¤\n\n"
            
            for idx, article in enumerate(articles[:10], 1):
                try:
                    title_element = article.find_element(By.CSS_SELECTOR, 'a.DY5T1d.RZIKme')
                    title = title_element.text
                    link = title_element.get_attribute('href')
                    
                    if title and link:
                        # ì˜ì–´ ê¸°ì‚¬ë§Œ í•„í„°ë§ (ì„ íƒì‚¬í•­)
                        if any(c.isascii() for c in title):
                            google_news += f"{idx}. <a href='{link}'>{title}</a>\n"
                except Exception as e:
                    print(f"êµ¬ê¸€ ë‰´ìŠ¤ íŒŒì‹± ì¤‘ ì—ëŸ¬: {e}")
                    continue
            
            google_news += "\n"
            return google_news
        except Exception as e:
            print(f"êµ¬ê¸€ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬: {e}")
            print(f"ì—ëŸ¬ ìƒì„¸: {str(e)}")
            try:
                print("\nPage source:")
                print(self.driver.page_source[:1000])  # í˜ì´ì§€ ì†ŒìŠ¤ ì¶œë ¥
            except:
                pass
            return "í•´ì™¸ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"

    def __del__(self):
        if hasattr(self, 'driver'):
            self.driver.quit()

async def main():
    collector = NewsCollector()
    await collector.collect_and_send()

if __name__ == "__main__":
    asyncio.run(main()) 